{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting coarse-grained classifiers from large CNN models.\n",
    "\n",
    "The following example shows how to extract coarse-grained classifiers from a fine-grained classifier pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sorted Class Similarity Matrix (SCSM) for finding the most similar classes to the chosen ones based on the original model weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SCSM(model):\n",
    "    \"\"\" Function returns a NumPy array with Sorted Class Similarity Matrix (SCSM)\n",
    "    Each row of this table stores a 'class similarity landscape' for a \n",
    "    particular class. We use cosine similarity as a similarity measure.\n",
    "    The first element of each row in SCSM is always this particular \n",
    "    class (cosine similarity equals 1 for the same element). \n",
    "    Then, the most similar classes are sorted in a descending order\n",
    "    (from the most to the least similar ones). We take into consideration\n",
    "    the similarity of model's last layer weights.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model - keras pre-trained  model with fine-grained classes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Sorted Class Similarity Matrix (SCSM) - a NumPy array\n",
    "    \"\"\"\n",
    "    #necessary imports:\n",
    "    import numpy as np\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    classes_i = np.moveaxis(model.layers[-1].get_weights()[0], 0, -1)\n",
    "    classes_j = np.moveaxis(model.layers[-1].get_weights()[0], 0, -1)\n",
    "    CSM = cosine_similarity(classes_i, classes_j)\n",
    "    # sort in a descending order and return indexes of classes\n",
    "    SCSM = np.argsort(-CSM, axis=1)\n",
    "    return SCSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read an example model from Keras (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of SCSM for MobileNetV2 is presented below. We can see here, that:\n",
    "* for class 0 (tench - a fish) the most similar classes are 391 (coho - a fish) and 389 (barracouta - also a fish)\n",
    "* for class 999 (a toilet tissue) the most similar classes are 700 (a paper towel) and 861 (a toilet seat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 391, 389, ..., 310, 840, 459],\n",
       "       [  1, 392, 393, ..., 764, 138, 573],\n",
       "       [  2,   3, 147, ..., 671,  18, 655],\n",
       "       ...,\n",
       "       [997, 947, 994, ..., 514, 442, 459],\n",
       "       [998, 987, 994, ..., 880, 981, 245],\n",
       "       [999, 700, 861, ..., 538,  27, 935]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_SCSM(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a dataset (we use image_dataset_from_directory from tf.keras.preprocessing to create a generator). In the example below, we use our own very small dataset, but to gather the results for the purpose of our paper, we used Kaggle Dogs vs. Cats dataset (see https://www.kaggle.com/c/dogs-vs-cats) - it has the same format as our tiny example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# set a correct image size for a network (MobileNetV2)\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "normalized_ds = test_ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# here, we read the labels for testing (correct only when shuffle is False)\n",
    "labels = np.concatenate([y for x, y in normalized_ds], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coarse_grained_model(model, init_classes, k_most_similar_classes):\n",
    "    \"\"\" Function takes a pre-trained fine-grained CNN model as an argument and returns\n",
    "    a coarse-grained model built using the base pre-trained model. The new coarse-grained classes\n",
    "    are placed in the same order as the corresponding initialization classes in init_classes list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model - keras pre-trained model with fined-grained classes\n",
    "    init_classes - list of initialization class indexes\n",
    "    k_most_similar_classes - number of classes taken into consideration\n",
    "    while computing the weights for a particular coarse-grained class\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_dense_coarse - resulting keras model with coarse-grained classes\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    SCSM = create_SCSM(model)\n",
    "\n",
    "    coarse_grained_weights = []\n",
    "    coarse_grained_bias =[]\n",
    "\n",
    "    for init_class in init_classes:\n",
    "        k_most_similar_per_init_class = np.squeeze(np.expand_dims(SCSM[init_class], axis=1))[:k_most_similar_classes]\n",
    "        weights_for_init = np.mean(model.layers[-1].get_weights()[0][:, k_most_similar_per_init_class], axis=1)\n",
    "        bias_for_init = np.mean(model.layers[-1].get_weights()[1][k_most_similar_per_init_class], axis=0)\n",
    "\n",
    "        coarse_grained_weights.append(weights_for_init)\n",
    "        coarse_grained_bias.append(bias_for_init)\n",
    "\n",
    "    new_weights = np.moveaxis(np.array(coarse_grained_weights), 0, -1)\n",
    "    new_biases = np.array(coarse_grained_bias)   \n",
    "\n",
    "    new_number_of_classes = len(init_classes)\n",
    "    new_dense_coarse = tf.keras.layers.Dense(new_number_of_classes, activation='softmax')(model.layers[-2].output)\n",
    "    new_dense_coarse = tf.keras.models.Model(inputs=model.input, outputs=new_dense_coarse)\n",
    "    new_dense_coarse.layers[-1].set_weights([new_weights, new_biases])\n",
    "    \n",
    "    return new_dense_coarse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters values:\n",
    "* k_most_similar_classes - number of the most similar classes to the init classes taken into consideration in the process of weight and bias matrices computation - we take 3 classes in the example below\n",
    "* init_classes - a list of initialization classes for a coarse-grained classifier. We take one cat breed (Persian cat - index 283) and one dog breed (Eskimo dog, husky - index 248). See https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a for a list of Imagenet labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_most_similar_classes = 3 #param\n",
    "init_classes = [283, 248] #param\n",
    "coarse_grained_model = create_coarse_grained_model(model=model, init_classes=init_classes, k_most_similar_classes=k_most_similar_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 979ms/step\n",
      "Accuracy\n",
      "0.85\n",
      "Confusion matrix\n",
      "[[0.8 0.2]\n",
      " [0.1 0.9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "predictions = coarse_grained_model.predict(normalized_ds)\n",
    "true_y =  np.argmax(labels, axis=1)\n",
    "predicted_y = np.argmax(predictions, axis=1)\n",
    "print('Accuracy')\n",
    "print(accuracy_score(true_y, predicted_y))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(true_y, predicted_y, normalize='true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
