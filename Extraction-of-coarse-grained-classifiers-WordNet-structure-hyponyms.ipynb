{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting coarse-grained classifiers from large CNN models.\n",
    "\n",
    "The following example shows how to extract coarse-grained classifiers from a fine-grained classifier pretrained on ImageNet.\n",
    "\n",
    "In the presented strategy, we use all the available hyponyms (in ImageNet) of each desired coarse-grained class. We find all the hyponyms (sub-categories) using WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we include the implementation of the function that allows to find all the hyponyms (sub-classes) of a given WordNet node. We use the nltk WordNet implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyponyms(hypernym_name):\n",
    "    \"\"\"\n",
    "    Function can be used to find all the hyponyms of a given WordNet node, \n",
    "    which is a hypernym of some classes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    hypernym_name - name of a WordNet node for which we aim to find all available \n",
    "    hyponyms in ImageNet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ids_array - a NumPy array with ImageNet ids of desired fine-grained classes (hyponyms)\n",
    "    \"\"\"\n",
    "    hyponyms = wn.synsets(hypernym_name)[0]\n",
    "    hyponyms = set([i for i in hyponyms.closure(lambda s:s.hyponyms())])\n",
    "    offsets = []\n",
    "    imagenet_classes = decode_predictions(to_categorical(np.expand_dims(np.array(range(1000)), axis=-1), num_classes=1000), top=1)\n",
    "\n",
    "    for c in imagenet_classes:\n",
    "        offsets.append(int(c[0][0].split('n')[1]))\n",
    "    \n",
    "    ids = []\n",
    "    for idx, o in enumerate(offsets):\n",
    "        isadoggo = wn.synset_from_pos_and_offset('n', int(o))\n",
    "        if isadoggo in hyponyms:\n",
    "            ids.append(idx)\n",
    "    ids_array = np.array(ids)\n",
    "    return ids_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read an example model from Keras (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a dataset (we use image_dataset_from_directory from tf.keras.preprocessing to create a generator). In the example below, we use our own very small dataset, but to gather the results for the purpose of our paper, we used Kaggle Dogs vs. Cats dataset (see https://www.kaggle.com/c/dogs-vs-cats) - it has the same format as our tiny example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 files belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\kfilus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# set a correct image size for a network (MobileNetV2)\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "normalized_ds = test_ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "\n",
    "# here, we read the labels for testing (correct only when shuffle is False)\n",
    "labels = np.concatenate([y for x, y in normalized_ds], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function provided below can be used to created coarse-grained classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coarse_grained_model(model, hypernyms):\n",
    "    \"\"\" Function takes a pre-trained fine-grained CNN model as an argument and returns\n",
    "    a coarse-grained model built using the base pre-trained model. The new coarse-grained classes\n",
    "    are placed in the same order as the corresponding hypernyms (coarse-grained classes)\n",
    "    in hypernyms list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model - keras pre-trained model with fined-grained classes\n",
    "    hypernyms - list of hypernyms - coarse-grained class\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_dense_coarse - resulting keras model with coarse-grained classes\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    coarse_grained_weights = []\n",
    "    coarse_grained_bias =[]\n",
    "\n",
    "    for hyp in hypernyms:\n",
    "        hyponyms = find_hyponyms(hypernym_name=hyp)\n",
    "        weights_for_init = np.mean(model.layers[-1].get_weights()[0][:, hyponyms], axis=1)\n",
    "        bias_for_init = np.mean(model.layers[-1].get_weights()[1][hyponyms], axis=0)\n",
    "\n",
    "        coarse_grained_weights.append(weights_for_init)\n",
    "        coarse_grained_bias.append(bias_for_init)\n",
    "\n",
    "    new_weights = np.moveaxis(np.array(coarse_grained_weights), 0, -1)\n",
    "    new_biases = np.array(coarse_grained_bias)   \n",
    "\n",
    "    new_number_of_classes = len(hypernyms)\n",
    "    new_dense_coarse = tf.keras.layers.Dense(new_number_of_classes, activation='softmax')(model.layers[-2].output)\n",
    "    new_dense_coarse = tf.keras.models.Model(inputs=model.input, outputs=new_dense_coarse)\n",
    "    new_dense_coarse.layers[-1].set_weights([new_weights, new_biases])\n",
    "    \n",
    "    return new_dense_coarse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters values:\n",
    "* hypernyms - a list of names for a coarse-grained classifier. They have to be WordNet nodes and the model to be modified has to include some of their hyponyms (e.g. for WordNet node dog, we have numerous ImageNet classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernyms = ['cat', 'dog'] #coarse-grained classes in the alphabetical order (similar to folder names)\n",
    "coarse_grained_model = create_coarse_grained_model(model=model, hypernyms=hypernyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 940ms/step\n",
      "Accuracy\n",
      "0.7\n",
      "Confusion matrix\n",
      "[[0.9 0.1]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "predictions = coarse_grained_model.predict(normalized_ds)\n",
    "true_y =  np.argmax(labels, axis=1)\n",
    "predicted_y = np.argmax(predictions, axis=1)\n",
    "print('Accuracy')\n",
    "print(accuracy_score(true_y, predicted_y))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(true_y, predicted_y, normalize='true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
